# Отчет: Реализация ограничения истории сообщений в SDK Yandex Cloud ML

## Общая задача

Реализовать функционал ограничения истории сообщений для ассистентов, чтобы при каждом запросе использовались только последние N сообщений из истории диалога.

## Вариант А: Глобальная настройка на ассистента (первая попытка)

### Описание подхода

Настройка применяется один раз при создании или получении ассистента через метод `assistant.update()`. После этого все последующие вызовы `assistant.run(thread)` автоматически используют эту настройку.

### Выполненные изменения

#### 1. Файл: `src/services/langgraph_service.py`

**Добавлен импорт:**
```python
from yandex_cloud_ml_sdk.assistants import LastMessagesPromptTruncationStrategy
```

**Изменения в методе `create_assistant`:**
- После создания ассистента и обновления инструкции добавлен вызов `assistant.update()` с параметрами:
  - `max_prompt_tokens=7000` - максимальное количество токенов в промпте
  - `prompt_truncation_strategy=LastMessagesPromptTruncationStrategy(num_messages=20)` - стратегия обрезки: только последние 20 сообщений

**Изменения в методе `get_or_create_assistant`:**
- Для существующих ассистентов (когда инструменты совпадают) добавлен вызов `assistant.update()` с теми же параметрами ограничения истории

### Преимущества подхода

- Настройка применяется один раз, дальше работает автоматически
- Не нужно передавать параметры при каждом вызове `run()`
- Проще в использовании

### Недостатки подхода

- Нельзя динамически менять количество сообщений для разных запросов
- Все ассистенты получают одинаковые настройки
- Меньше гибкости в управлении

### Проблемы, с которыми столкнулись

1. **Ошибка импорта:** Первоначально использовался путь `yandex_cloud_ml_sdk.assistants.prompttruncationoptions`, который не работал. Исправлено на `yandex_cloud_ml_sdk.assistants`.

---

## Вариант Б: Динамическая настройка на каждый run (финальная реализация)

### Описание подхода

Настройка передается как параметры при каждом вызове `assistant.run()`. Это позволяет динамически управлять количеством сообщений для каждого конкретного запроса.

### Выполненные изменения

#### 1. Файл: `src/services/langgraph_service.py`

**Удален импорт:**
```python
# Удалено:
from yandex_cloud_ml_sdk.assistants import LastMessagesPromptTruncationStrategy
```

**Удалены настройки из метода `create_assistant`:**
- Убран блок кода с `assistant.update()` для настройки ограничения истории

**Удалены настройки из метода `get_or_create_assistant`:**
- Убран блок кода с `assistant.update()` для настройки ограничения истории для существующих ассистентов

#### 2. Файл: `src/agents/base_agent.py`

**Добавлен импорт:**
```python
from yandex_cloud_ml_sdk.assistants import LastMessagesPromptTruncationStrategy
```

**Изменения в методе `_execute_request`:**

**Первое место вызова `assistant.run()` (строка ~151):**
```python
# Было:
run = self.assistant.run(thread)

# Стало:
run = self.assistant.run(
    thread,
    custom_prompt_truncation_strategy=LastMessagesPromptTruncationStrategy(
        num_messages=20
    ),
    custom_max_prompt_tokens=7000,
)
```

**Второе место вызова `assistant.run()` (строка ~339):**
- Внутри цикла обработки JSON с инструментами, когда нужно запустить новый run после получения результата инструмента
- Добавлены те же параметры для ограничения истории

### Преимущества подхода

- **Гибкость:** Можно менять количество сообщений для каждого запроса
- **Динамическое управление:** Разные агенты или разные типы запросов могут использовать разное количество сообщений
- **Полный контроль:** Можно адаптировать под конкретную ситуацию

### Недостатки подхода

- Нужно передавать параметры при каждом вызове `run()`
- Больше кода в местах вызова

### Технические детали

**Параметры, передаваемые в `assistant.run()`:**
- `custom_prompt_truncation_strategy` - стратегия обрезки промпта
  - `LastMessagesPromptTruncationStrategy(num_messages=20)` - оставляет только последние 20 сообщений
- `custom_max_prompt_tokens` - максимальное количество токенов в промпте (7000)

**Места применения:**
1. Основной вызов `run()` при обработке запроса пользователя
2. Повторный вызов `run()` после выполнения инструмента (когда SDK возвращает инструмент в JSON)

---

## Сравнение вариантов

| Характеристика | Вариант А (глобально) | Вариант Б (на каждый run) |
|----------------|----------------------|---------------------------|
| Гибкость | Низкая | Высокая |
| Простота использования | Выше | Ниже |
| Динамическое управление | Нет | Да |
| Количество изменений кода | Меньше | Больше |
| Применение | Один раз при создании | При каждом вызове |

---

## Итоговое решение

Выбран **Вариант Б** (динамическая настройка на каждый run), так как он предоставляет больше гибкости и контроля над процессом обработки запросов.

### Финальная структура изменений

1. **`src/services/langgraph_service.py`** - убраны все настройки ограничения истории
2. **`src/agents/base_agent.py`** - добавлены параметры в вызовы `assistant.run()`

### Результат

Теперь при каждом вызове `assistant.run()` используется только последние 20 сообщений из истории диалога, с дополнительным ограничением по токенам до 7000. Это позволяет:
- Контролировать размер контекста для каждого запроса
- Адаптировать под разные сценарии использования
- Оптимизировать использование токенов

---

## Дата создания отчета

2024

